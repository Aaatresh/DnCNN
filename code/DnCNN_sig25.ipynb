{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Czo4T0ierj-G"
   },
   "outputs": [],
   "source": [
    "import torch as tor\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.measure import compare_ssim as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0dd4ox6y0me"
   },
   "outputs": [],
   "source": [
    "def calc_total_mean(datafiles,num_chn = 3,verbose = False):\n",
    "\n",
    "    \"\"\"\n",
    "        Find the total mean for mean centering\n",
    "    \"\"\"\n",
    "    \n",
    "    img_sum = 0\n",
    "    num_files = len(datafiles)\n",
    "\n",
    "    for e,file in enumerate(datafiles):\n",
    "\n",
    "        if(num_chn == 3):\n",
    "            img = cv2.resize(cv2.imread(file),(256,256))\n",
    "            img_sum += img\n",
    "        elif(num_chn == 1):\n",
    "            img = cv2.imread(file,0)\n",
    "            img_sum += img\n",
    "        else:\n",
    "            assert \"Incorrect number of channels\"\n",
    "\n",
    "        if(verbose):\n",
    "            print(e,file)\n",
    "\n",
    "\n",
    "    return np.float32(img_sum) / num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7X8xeuA2ukSO"
   },
   "outputs": [],
   "source": [
    "class dncnn(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "        DnCNN module\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self,in_channels = 3,depth = 17):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        layers.append(nn.Conv2d(in_channels = in_channels,out_channels = 64,kernel_size = (3,3),padding = 1))\n",
    "        layers.append(nn.ReLU(inplace = True))\n",
    "\n",
    "        for l in range(depth - 2):\n",
    "            layers.append(nn.Conv2d(in_channels = 64,out_channels = 64,kernel_size = (3,3),padding = 1))\n",
    "            layers.append(nn.ReLU(inplace = True))\n",
    "            layers.append(nn.BatchNorm2d(64))\n",
    "\n",
    "        layers.append(nn.Conv2d(in_channels = 64,out_channels = in_channels,kernel_size = (3,3),padding = 1))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self,y):\n",
    "\n",
    "        out = self.net(y)\n",
    "        return y - out\n",
    "\n",
    "    def init_weights(self):\n",
    "\n",
    "        for m in self.modules():\n",
    "\n",
    "            if(isinstance(m,nn.Conv2d)):\n",
    "                nn.init.orthogonal_(m.weight)\n",
    "\n",
    "                if(m.bias is not None):\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "\n",
    "            elif(isinstance(m,nn.BatchNorm2d)):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9e7cZVo10q4G"
   },
   "outputs": [],
   "source": [
    "def getpatch(img,patchsize):\n",
    "\n",
    "    \"\"\"\n",
    "        Obtains 40 x 40 patches to train the network\n",
    "    \"\"\"\n",
    "    \n",
    "    h,w,_ = img.shape\n",
    "    x,y = np.random.randint(0,w - patchsize),np.random.randint(0,h - patchsize)\n",
    "\n",
    "    patch = img[y:y + patchsize,x:x + patchsize,:]\n",
    "\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yXDgv9QSwDNy"
   },
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "        Main dataset class\n",
    "    \"\"\"\n",
    "    \n",
    "    total_mean = 0.0\n",
    "\n",
    "    def __init__(self,data_dir,data_size = -1,patchsize = 40,sigma = 25,phase = \"\",apply_transform = False):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.datafiles = os.listdir(data_dir)\n",
    "        self.datafiles = [os.path.join(data_dir,x) for x in self.datafiles]\n",
    "\n",
    "        if(data_size == -1):\n",
    "            self.data_size = len(self.datafiles)\n",
    "\n",
    "        if(phase == \"train\"):\n",
    "            dataset.total_mean = tor.from_numpy(calc_total_mean(self.data_files))\n",
    "            dataset.total_mean = dataset.total_mean.permute(2,0,1)\n",
    "\n",
    "        self.patchsize = patchsize\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        imgname = self.datafiles[idx]\n",
    "        img = np.float32(cv2.imread(imgname,1))\n",
    "        clean_patch = getpatch(img,self.patchsize)\n",
    "        clean_patch = tor.from_numpy(clean_patch).permute(2,0,1)\n",
    "\n",
    "        noise = tor.randn(clean_patch.size()).mul_(self.sigma)\n",
    "\n",
    "        noisy_patch = clean_patch + noise\n",
    "\n",
    "        return noisy_patch,clean_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X7blbwBV7GPE"
   },
   "outputs": [],
   "source": [
    "def train(net,epochs,dataloaders,hyper_params,reset = True,save = False):\n",
    "\n",
    "    \"\"\"\n",
    "        Training function\n",
    "    \"\"\"\n",
    "    \n",
    "    if(reset):\n",
    "        net.init_weights()\n",
    "        print(\"/////////////// Weights Reset \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "\n",
    "    trainloader,valloader = dataloaders\n",
    "\n",
    "    lr,reg = hyper_params\n",
    "\n",
    "    optimizer = tor.optim.Adam(net.parameters(),lr = lr,weight_decay = reg)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        batch_losses = []\n",
    "\n",
    "        for batch_idx,(noisy_patch,clean_patch) in enumerate(trainloader):\n",
    "\n",
    "            noisy_patch,clean_patch = noisy_patch.to(device),clean_patch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = net(noisy_patch)\n",
    "            loss = criterion(out,clean_patch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "        print(\"Epoch: \",epoch,\"train loss: \",np.mean(batch_losses))\n",
    "\n",
    "        net.eval()\n",
    "        with tor.no_grad():\n",
    "            \n",
    "            batch_losses = []\n",
    "            \n",
    "            for batch_idx,(valdata,vallabel) in enumerate(valloader):\n",
    "\n",
    "                valdata,vallabel = valdata.to(device),vallabel.to(device)\n",
    "\n",
    "                valout = net(valdata)\n",
    "                loss = criterion(valout,vallabel)\n",
    "\n",
    "                batch_losses.append(loss.item())\n",
    "\n",
    "            print(\"Val Loss: \",np.mean(batch_losses))\n",
    "    \n",
    "\n",
    "        print(\"-------------------------------------------------------------------------\")\n",
    "        net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVbwa-SOopjP"
   },
   "outputs": [],
   "source": [
    "traindir = \"./dncnn_dataset/train/\"\n",
    "trainset = dataset(traindir)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 32,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3iVJLbV6lwJF"
   },
   "outputs": [],
   "source": [
    "valdir = \"./dncnn_dataset/val/\"\n",
    "valset = dataset(valdir)\n",
    "valloader = torch.utils.data.DataLoader(valset,batch_size = 32,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1p6kQ3s9usc7"
   },
   "outputs": [],
   "source": [
    "device = tor.device(\"cuda:0\" if tor.cuda.is_available() else \"cpu\")\n",
    "net = dncnn().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gco77vzyjTDI",
    "outputId": "4feaa4f0-0027-4f34-c3fe-5d4d0afdd67f"
   },
   "outputs": [],
   "source": [
    "state = tor.load(\"/content/drive/My Drive/datasets/dncnn_dataset/dncnn_chk.pth.tar\")\n",
    "net.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "O5F2lzfKuhy5",
    "outputId": "6d574598-e740-4d6d-8b03-07d65d00baa1"
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "reg = 0.0\n",
    "reset = True\n",
    "hyper_params = [lr,reg]\n",
    "\n",
    "dataloaders = [trainloader,valloader]\n",
    "\n",
    "train(net,epochs,dataloaders,hyper_params,reset = reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DcsXlJvHvA4f"
   },
   "outputs": [],
   "source": [
    "testdir = \"./dncnn_dataset/test/Set12/\"\n",
    "testset = dataset(valdir)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size = 32,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "qtmJt_8VBnsm",
    "outputId": "4d02c0f8-6ef5-4fc5-f307-78e8251af4c4"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "net.eval()\n",
    "with tor.no_grad():\n",
    "    \n",
    "    batch_losses = []\n",
    "    \n",
    "    for batch_idx,(testdata,testlabel) in enumerate(testloader):\n",
    "\n",
    "        testdata,testlabel = testdata.to(device),testlabel.to(device)\n",
    "\n",
    "        testout = net(testdata)\n",
    "        loss = criterion(testout,testlabel)\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "    print(\"Test Loss: \",np.mean(batch_losses))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "_ = net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dlio6_XNB_8y"
   },
   "outputs": [],
   "source": [
    "state = net.state_dict()\n",
    "\n",
    "tor.save(state,\"/content/drive/My Drive/datasets/dncnn_dataset/dncnn_chk.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NfD8IPzJyKPr"
   },
   "outputs": [],
   "source": [
    "def psnr(img1, img2,PIXEL_MAX):\n",
    "    \"\"\"\n",
    "        Calculates the peak signal-to-noise ratio of 2 images\n",
    "        \n",
    "        Arguments:\n",
    "            img1: Image1\n",
    "            img2: Image2\n",
    "            \n",
    "        Returns:\n",
    "            The peak signal-to-noise ratio of the 2 images\n",
    "    \"\"\"\n",
    "    mse = np.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    \n",
    "    return 20 * np.log10(PIXEL_MAX / np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "MtvG7tIeC556",
    "outputId": "54d18916-201c-49f4-96fa-4e36328d53ea"
   },
   "outputs": [],
   "source": [
    "sigma = 35\n",
    "\n",
    "img = np.float32(cv2.imread(\"./dncnn_dataset/test/Set12/06.png\")) \n",
    "img = tor.from_numpy(img)\n",
    "\n",
    "noise = tor.randn(img.size()).mul_(sigma)\n",
    "\n",
    "noisy_img = img + noise\n",
    "\n",
    "noisy_img_n = noisy_img.numpy()\n",
    "\n",
    "noisy_img1 = ((noisy_img_n - noisy_img_n.min()) / (noisy_img_n.max() - noisy_img_n.min()))\n",
    "img1 = img.detach().clone().cpu().numpy()\n",
    "img1 = ((img1 - img1.min()) / (img1.max() - img1.min()))\n",
    "\n",
    "print(\"input psnr: \",psnr(noisy_img1,img1,1.0))\n",
    "print(\"input ssim: \",ssim(noisy_img1,img1,multichannel = True))\n",
    "\n",
    "plt.imshow(noisy_img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "TE6KGXIDcMmG",
    "outputId": "d6da9bfc-b036-438f-e92f-0691eaa08db2"
   },
   "outputs": [],
   "source": [
    "h,w,_ = noisy_img.size()\n",
    "noisy_img = noisy_img.permute(2,0,1).unsqueeze(0).to(device)\n",
    "\n",
    "res = net(noisy_img)\n",
    "clean_img = res.squeeze().permute(1,2,0)\n",
    "clean_img = clean_img.detach().clone().cpu().numpy()\n",
    "\n",
    "# img1 = img.detach().clone().cpu().numpy()\n",
    "\n",
    "clean_img1 = (clean_img - clean_img.min()) / (clean_img.max() - clean_img.min())\n",
    "# img1 = (img1 - img1.min()) / (img1.max() - img1.min())\n",
    "\n",
    "print(\"psnr: \",psnr(clean_img1,img1,1.0))\n",
    "print(\"ssim: \",ssim(clean_img1,img1,multichannel = True))\n",
    "\n",
    "plt.imshow(clean_img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkkeJTgmrkQI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DnCNN_sig25.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
